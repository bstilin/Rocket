{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Rocket_mv.jl\")\n",
    "include(\"RocketHelperFunctions_mv.jl\")\n",
    "using MLJ\n",
    "using MLJLinearModels\n",
    "using ARFFFiles,DataFrames,CategoricalArrays\n",
    "using Catch22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for data import and regression classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stores multivariate data in an array with structure [samples, dimensions, timepoints].\n",
    "### Parameters\n",
    "    1. data : DataFrame\n",
    "        -a collection of imported single channel files\n",
    "    2. dims : int\n",
    "        -the number of channels/dimensions per sample\n",
    "    3. leng : int\n",
    "        -the number of timepoints in each sample.\n",
    "\n",
    "### Returns\n",
    "    - An array in format [samples, dimensions, timepoints] for use with multivariate rocket transform functions\n",
    "\"\"\"\n",
    "function prep_data(data, dims, leng) \n",
    "    cells = size(data[1])[1]\n",
    "    X = zeros((cells, dims, leng))\n",
    "    for i in 1:cells\n",
    "        for j in 1:dims\n",
    "            X[i,j,:] = Array(data[j][i,1:leng])\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "#this should work for any problem (single or multichannel input, multiclass or binary classification), based on MLJLinearModels implementation\n",
    "\"\"\"\n",
    "Builds a tuned logistic regression classifier model regularized with an l1 penalty.\n",
    "\n",
    "### Parameters:\n",
    "    1. X : DataFrame\n",
    "        -a dataframe containing kernel-transformed training data with labels\n",
    "    2. Y : CategoricalArray\n",
    "        -labels for each training example\n",
    "    3. l : int\n",
    "        -lower bound for lambda\n",
    "    4. u : int\n",
    "        -upper bound for lambda\n",
    "    5. num_models : int\n",
    "        -number of models to compare for hyperparameter tuning\n",
    "    6. num_folds : int\n",
    "        -number of cross-validation folds for hyperparameter tuning\n",
    "    \n",
    "### Returns:\n",
    "    -a MLJ logistic regression classifier model trained on (X, Y)\n",
    "\"\"\"\n",
    "function regression_fitting(X::DataFrame, Y::CategoricalArray,l::Float64, u::Float64, num_models::Int, num_folds::Int)\n",
    "    \n",
    "    log_classifier = LogisticClassifier(penalty=:l1)\n",
    "\n",
    "    lambda_range = range(log_classifier, :lambda, lower=l, upper=u) #Defining range object for hyperparameter tuning\n",
    "    self_tuning_model= TunedModel(model=log_classifier,\n",
    "        resampling = CV(nfolds=num_folds, rng=1234),#rng seeds to standardize\n",
    "        tuning = RandomSearch(), #change to Grid() for grid search.\n",
    "        ranges = lambda_range,\n",
    "        n=num_models);\n",
    "\n",
    "\n",
    "    mach = machine(self_tuning_model, X,CategoricalArray(Y))\n",
    "    \n",
    "    fit!(mach) #Fit model! NOTE defaults to minimizing cross-entropy loss for training.\n",
    "    return mach\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "A function to import training and testing data from a data folder (via the links in each example).\n",
    "\n",
    "### Parameters:\n",
    "    1. ds_string : String\n",
    "        -the file name prefix for each data file.\n",
    "    2. n_dims : int\n",
    "        -the number of channels per sample to read\n",
    "    3. starts_at : int\n",
    "        -the column at which timepoint data begins in each file \n",
    "    4. train : boolean\n",
    "        -whether the import is for training or testing data\n",
    "    5. standardize : boolean\n",
    "        -whether to standardize each sample (example - example_mean)/(example_sd)\n",
    "    6. series_length : int\n",
    "        -how many timepoints to inclue for each sample\n",
    "    7. label_column : int\n",
    "        -the column containing label data\n",
    "### Returns:\n",
    "    -A tuple (g, labels_train) containing the desired multivariate data array g and the labels for this dataset.\n",
    "\"\"\"\n",
    "function import_data(ds_string::String, n_dims::Int64, starts_at::Int64 = 1, train::Bool = true, standardize::Bool = false, series_length::Int64 = 144, label_column::Int64 = 145)\n",
    "    channels_arr = []\n",
    "    train_string = \"\"\n",
    "    if train == true\n",
    "        train_string = \"TRAIN\"\n",
    "    else\n",
    "        train_string = \"TEST\"\n",
    "    end\n",
    "        \n",
    "    for i in range(starts_at, n_dims)\n",
    "        df = ARFFFiles.load(DataFrame, \"../data/\"*ds_string * string(i)*\"_\"*train_string*\".arff\")\n",
    "        push!(channels_arr,df)\n",
    "    end\n",
    "    labelsn = channels_arr[1][:,label_column]\n",
    "    g = prep_data(channels_arr, n_dims, series_length);\n",
    "    if standardize\n",
    "        g, = normalize_data_matrix_mv(g)\n",
    "    end\n",
    "    return g, labels\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Multivariate Time Series applications of ROCKET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mulivariate time series, we take the approach of generating rectangular kernels in a manner similar to the single channel case. Padding remains the same for all channels, as does dilation -- this limits the use of kernels at multiple timescales per channel. These limitations are necessary for computational efficiency.\n",
    "\n",
    "Kernels for multivariable data are generated by constant dilation, padding, and bias per channel, with normally-distributed weights.  The kernels cover significantly less of the search space as the channel count increases, and thus results become much less stable (see: https://en.wikipedia.org/wiki/Curse_of_dimensionality).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use examples from the Time Series Machine Learning Website (http://www.timeseriesclassification.com/index.php) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: ArticularyWordRecognitionDimension\n",
    "This dataset has 9 channels and 25 classes, making it a demonstration of the disutility of ROCKET for data with an excess of input channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "ds_string = \"ArticularyWordRecognitionDimension\"\n",
    "n_dims = 9\n",
    "starts_at = 1\n",
    "series_length = 144\n",
    "\n",
    "X_train, Y_train = import_data(ds_string, n_dims, starts_at, true, true, series_length,145)\n",
    "X_test, Y_test = import_data(ds_string, n_dims, starts_at, false, true, series_length,145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel generation and ROCKET Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generate ROCKET kernels\n",
    "kers = 10000\n",
    "K = generate_kernels_mv(series_length,n_dims,kers);\n",
    "\n",
    "#generate column names for each kernel -- for tracking relevant kernels later.\n",
    "K_symbols = cat([Symbol(k.name,\"max\") for k in K], [Symbol(k.name,\"ppv\") for k in K],dims=1);\n",
    "\n",
    "#transform data, store in dataframe with column labels for each kernel feature.\n",
    "X_train_transform = Rocket_transform_mv(X_train,K)[1];\n",
    "df_train = DataFrame(X_train_transform, K_symbols);\n",
    "X_test_transform = Rocket_transform_mv(X_test,K)[1];\n",
    "df_test = DataFrame(X_test_transform, K_symbols);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call regression fitting function on training data\n",
    "mach = regression_fitting(df_train, Y_train, 0.0, 1.0, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred = predict_mode(mach,df_test)\n",
    "y_train_pred = predict_mode(mach, df_train)\n",
    "\n",
    "#confusion matrices\n",
    "MLJ.confusion_matrix(y_pred, Y_test)\n",
    "#MLJ.confusion_matrix(y_train_pred, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred .== Y_test)/length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=fitted_params(mach)\n",
    "best_coefs=params.best_fitted_params.coefs #coefs of model with lowest log_loss\n",
    "best_coef_sum_vals = [c[2][1] for c in best_coefs]\n",
    "sum(best_coef_sum_vals.== 0)\n",
    "r = best_coef_sum_vals[best_coef_sum_vals .!= 0]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1a: Augmenting ROCKET with catch22\n",
    "\n",
    "catch22 {`Lubba2019`, https://doi.org/10.1007/s10618-019-00647-x) is a collection of discriminative time series features generated from the highly comparative time-series analysis (hctsa https://zenodo.org/badge/latestdoi/10790340) features.  These can be used to gain a better understanding of how common time series features, alongside the frequency, shape, and correlation features from ROCKET, contribute to classification. Below is a demonstration of how the ROCKET transform matrix can be augmented with these 22 additional features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles correct formatting for the catch22 function\n",
    "function apply_catch22(X::Array, channel = 1)\n",
    "    return catch22(transpose(X[:,channel,:]))\n",
    "end\n",
    "#generate catch22 values per channel for all samples, return updated dataframe.\n",
    "function gen_all(X::Array, df_to_add)\n",
    "    df_new = copy(df_to_add)\n",
    "    channel_count = size(X)[2]\n",
    "    for i in 1:channel_count\n",
    "        res = apply_catch22(X, i)\n",
    "        setproperty!.(Ref(df_new), [string(la)*\"_c\"*string(i) for la in getnames(res)], eachrow(res.data));\n",
    "    end\n",
    "    return df_new\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate catch22\n",
    "df_train_with_catch22 = gen_all(X_train, df_train) \n",
    "df_test_with_catch22 = gen_all(X_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = regression_fitting(df_train_with_catch22[:,kers * 2:kers * 2 + 22 * n_dims], Y_train, 0.0, 1.0, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred = predict_mode(mach,df_test_with_catch22[:,kers * 2:kers * 2 + 22 * n_dims])\n",
    "y_train_pred = predict_mode(mach, df_train_with_catch22[:,kers * 2:kers * 2 + 22 * n_dims])\n",
    "\n",
    "#confusion matrices\n",
    "MLJ.confusion_matrix(y_pred, Y_test)\n",
    "MLJ.confusion_matrix(y_train_pred, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred .==Y_test)/length(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = regression_fitting(df_train_with_catch22, Y_train, 0.0, 1.0, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred = predict_mode(mach,df_test_with_catch22)\n",
    "y_train_pred = predict_mode(mach, df_train_with_catch22)\n",
    "\n",
    "#confusion matrices\n",
    "MLJ.confusion_matrix(y_pred, Y_test)\n",
    "#MLJ.confusion_matrix(y_train_pred, Y_train)\n",
    "sum(y_pred .==Y_test)/length(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Atrial Fibrillation\n",
    "\n",
    "In this case, we take the Atrial Fibrillation dataset from http://www.timeseriesclassification.com/description.php?Dataset=AtrialFibrillation\n",
    "This has a small training and testing dataset, with three classes and two channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CategoricalArrays\n",
    "#import data\n",
    "ds_string = \"AtrialFibrillationDimension\"\n",
    "n_dims = 2\n",
    "starts_at = 1\n",
    "series_length = 640\n",
    "\n",
    "X_train, Y_train = import_data(ds_string, n_dims, starts_at, true, true, series_length,641)\n",
    "X_test, Y_test = import_data(ds_string, n_dims, starts_at, false, true, series_length,641)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generate ROCKET kernels\n",
    "kers = 5000\n",
    "K = generate_kernels_mv(series_length,n_dims,kers);\n",
    "\n",
    "#generate column names for each kernel -- for tracking relevant kernels later.\n",
    "K_symbols = cat([Symbol(k.name,\"max\") for k in K], [Symbol(k.name,\"ppv\") for k in K],dims=1);\n",
    "\n",
    "#transform data, store in dataframe with column labels for each kernel feature.\n",
    "X_train_transform = Rocket_transform_mv(X_train,K)[1];\n",
    "df_train = DataFrame(X_train_transform, K_symbols);\n",
    "X_test_transform = Rocket_transform_mv(X_test,K)[1];\n",
    "df_test = DataFrame(X_test_transform, K_symbols);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call regression fitting function on training data\n",
    "mach = regression_fitting(df_train, Y_train, 0.0, 1.0, 10, 5,\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prediction\n",
    "y_pred = predict_mode(mach,df_test)\n",
    "y_train_pred = predict_mode(mach, df_train)\n",
    "\n",
    "#confusion matrices\n",
    "MLJ.confusion_matrix(y_pred, Y_test)\n",
    "MLJ.confusion_matrix(y_train_pred, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred .==Y_test)/length(Y_test) #random chance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Pen Digits\n",
    "\n",
    "In this case, we take the Pen Digits dataset from http://www.timeseriesclassification.com/description.php?Dataset=PenDigits\n",
    "This has a large training and testing dataset, with ten classes and two channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CategoricalArrays\n",
    "#import data\n",
    "ds_string = \"PenDigitsDimension\"\n",
    "n_dims = 2\n",
    "starts_at = 1\n",
    "series_length = 8\n",
    "\n",
    "X_train, Y_train = import_data(ds_string, n_dims, starts_at, true, true, series_length,9)\n",
    "X_test, Y_test = import_data(ds_string, n_dims, starts_at, false, true, series_length,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generate ROCKET kernels\n",
    "kers = 5000\n",
    "K = generate_kernels_mv(series_length,n_dims,kers);\n",
    "\n",
    "#generate column names for each kernel -- for tracking relevant kernels later.\n",
    "K_symbols = cat([Symbol(k.name,\"max\") for k in K], [Symbol(k.name,\"ppv\") for k in K],dims=1);\n",
    "\n",
    "#transform data, store in dataframe with column labels for each kernel feature.\n",
    "X_train_transform = Rocket_transform_mv(X_train,K)[1];\n",
    "df_train = DataFrame(X_train_transform, K_symbols);\n",
    "X_test_transform = Rocket_transform_mv(X_test,K)[1];\n",
    "df_test = DataFrame(X_test_transform, K_symbols);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call regression fitting function on training data\n",
    "mach = regression_fitting(df_train, Y_train, 0.0, 1.0, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prediction\n",
    "y_pred = predict_mode(mach,df_test)\n",
    "y_train_pred = predict_mode(mach, df_train)\n",
    "\n",
    "#confusion matrices\n",
    "MLJ.confusion_matrix(y_pred, Y_test)\n",
    "#MLJ.confusion_matrix(y_train_pred, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred .==Y_test)/length(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0-rc2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0-rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
